{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing importing Files\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading File Data\n",
    "\n",
    "fileData=[]\n",
    "with open(\"Output.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        x = re.sub(\"=\", \" = \", line)\n",
    "        x = re.sub(\"  \",\" \", x)   \n",
    "        fileData.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['integer', 'integers', 'int', 'ints', 'float', 'floats', 'number', 'numbers', 'num', 'nums', 'variable', 'variables', 'var', 'vars', 'double', 'doubles'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading Shelf Data from \"Data Generator\"\n",
    "import shelve\n",
    "import os\n",
    "\n",
    "dest_file=\"NLP_Shelfv8//\" + \"Dict_Lists\" + \".shlf\"\n",
    "\n",
    "shelf = shelve.open(dest_file)\n",
    "\n",
    "dataType_number = shelf[\"dataType_number\"]\n",
    "dataType_char = shelf[\"dataType_char\"]\n",
    "dataType_list = shelf[\"dataType_list\"]\n",
    "dataType_bool = shelf[\"dataType_bool\"]\n",
    "dataType_class = shelf[\"dataType_class\"]\n",
    "dataType_void = shelf[\"dataType_void\"]\n",
    "dataType = shelf[\"dataType\"]\n",
    "\n",
    "variables_list = shelf[\"variables_list\"]\n",
    "\n",
    "scope_of_variable = shelf[\"scope_of_variable\"]\n",
    "\n",
    "operators = shelf[\"operators\"]\n",
    "\n",
    "command_declare = shelf[\"command_declare\"]\n",
    "command_print = shelf[\"command_print\"]\n",
    "command_input = shelf[\"command_input\"]\n",
    "\n",
    "func_prog = shelf[\"func_prog\"]\n",
    "\n",
    "special_class = shelf[\"special_class\"]\n",
    "special_function = shelf[\"special_function\"]\n",
    "\n",
    "shelf.close()\n",
    "\n",
    "#print(dataType_number, \"\\n\")\n",
    "#print(dataType, \"\\n\")\n",
    "#print(variables_list, \"\\n\")\n",
    "#print(scope_of_variable, \"\\n\")\n",
    "#print(operators, \"\\n\")\n",
    "#print(command_declare, \"\\n\")\n",
    "#print(command_print, \"\\n\")\n",
    "#print(command_input, \"\\n\")\n",
    "#print(func_prog, \"\\n\")\n",
    "#print(special_class, \"\\n\")\n",
    "#print(special_function, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Defining Patterns\n",
    "#{\"IN\":[\"\",\"s\"]}\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern1_1 = [{\"LOWER\":{\"IN\":dataType}}]\n",
    "matcher.add(\"DATATYPE\", None, pattern1_1)\n",
    "\n",
    "pattern2_1 = [{\"LOWER\":\"global\"}]\n",
    "pattern2_2 = [{\"LOWER\":\"local\"}]\n",
    "matcher.add(\"SCOPE\", None, pattern2_1, pattern2_2)\n",
    "\n",
    "pattern3_1 = [{\"LOWER\":{\"IN\":operators}}]\n",
    "pattern3_2 = [{\"LOWER\":{\"IN\":[\"additions\", \"adds\"]}}]\n",
    "pattern3_3 = [{\"LOWER\":{\"IN\":[\"subtractions\", \"subs\"]}}]\n",
    "pattern3_4 = [{\"LOWER\":{\"IN\":[\"minuses\", \"multiplies\", \"muls\"]}}]\n",
    "pattern3_5 = [{\"LOWER\":{\"IN\":[\"divides\", \"divs\"]}}]\n",
    "pattern3_6 = [{\"LOWER\":{\"IN\":[\"modulus\", \"moduluses\", \"mods\"]}}]\n",
    "matcher.add(\"OPERATOR\", None, pattern3_1, pattern3_2, pattern3_3, pattern3_4, pattern3_5, pattern3_6)\n",
    "\n",
    "pattern4_1 = [{\"LOWER\":{\"IN\":command_declare}}]\n",
    "pattern4_2 = [{\"LOWER\":{\"IN\":command_print}}]\n",
    "pattern4_3 = [{\"LOWER\":{\"IN\":command_input}}]\n",
    "pattern4_4 = [{\"LOWER\":{\"IN\":special_function}}]\n",
    "matcher.add(\"COMMAND\", None, pattern4_1, pattern4_2, pattern4_3, pattern4_4)\n",
    "\n",
    "pattern5_1 = [{\"LOWER\":{\"IN\":[\"function\",\"functions\"]}}]\n",
    "pattern5_2 = [{\"LOWER\":{\"IN\":[\"func\",\"funcs\"]}}]\n",
    "pattern5_3 = [{\"LOWER\":{\"IN\":[\"program\",\"programs\"]}}]\n",
    "pattern5_4 = [{\"LOWER\":{\"IN\":[\"programme\",\"programmes\"]}}]\n",
    "pattern5_5 = [{\"LOWER\":{\"IN\":[\"prog\",\"progs\"]}}]\n",
    "\n",
    "pattern5_1 = [{\"LOWER\":{\"IN\":func_prog}}]\n",
    "pattern5_2 = [{\"LOWER\":{\"IN\":[\"funcs\",\"functions\"]}}]\n",
    "pattern5_3 = [{\"LOWER\":{\"IN\":[\"programs\",\"programmes\",\"progs\"]}}]\n",
    "matcher.add(\"FUNC_PROG\", None, pattern5_1, pattern5_2, pattern5_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating Training Data\n",
    "\n",
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(fileData):\n",
    "    \n",
    "    #x = re.sub(\"=\", \" = \", doc)\n",
    "    #doc = re.sub(\"  \",\" \", x)\n",
    "    \n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    \n",
    "    #Modified Start\n",
    "    entity_label=[]\n",
    "    entity_label = [(nlp.vocab.strings[match_id]) for match_id, start, end in matcher(doc)]\n",
    "    #if entity_label!=[]:\n",
    "    #    print (entity_label)\n",
    "    entities = [(span.start_char, span.end_char, entity_label[index]) for index,span in enumerate(spans)]\n",
    "    \n",
    "    #for eachWord in entities:\n",
    "    #    print(\"Entities: {}\".format(eachWord))\n",
    "    \n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    \n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "    #Modified End\n",
    "    \n",
    "    '''\n",
    "    entities = [(span.start_char, span.end_char, \"INITIALIZATION\") for span in spans]\n",
    "    \n",
    "    for eachWord in entities:\n",
    "        print(\"Entities: {}\".format(eachWord))\n",
    "        \n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "    '''\n",
    "    \n",
    "\n",
    "#print(*TRAINING_DATA, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store to Data file for inspection\n",
    "with open(\"training_data.txt\",\"w\") as o_file:\n",
    "    for item in TRAINING_DATA:\n",
    "        o_file.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Applications\\miniconda3\\envs\\ME-NLP\\lib\\site-packages\\spacy\\language.py:635: UserWarning: [W033] Training a new parser or NER using a model with an empty lexeme normalization table. This may degrade the performance to some degree. If this is intentional or this language doesn't have a normalization table, please ignore this warning.\n",
      "  proc.begin_training(\n",
      "D:\\Applications\\miniconda3\\envs\\ME-NLP\\lib\\site-packages\\spacy\\language.py:635: UserWarning: [W034] Please install the package spacy-lookups-data in order to include the default lexeme normalization table for the language 'en'.\n",
      "  proc.begin_training(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 40557.592681884766}\n",
      "{'ner': 27162.497303009033}\n",
      "{'ner': 19044.878437042236}\n"
     ]
    }
   ],
   "source": [
    "#Training Loop\n",
    "import random\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "ner.add_label(\"DATATYPE\")\n",
    "ner.add_label(\"SCOPE\")\n",
    "ner.add_label(\"OPERATOR\")\n",
    "ner.add_label(\"COMMAND\")\n",
    "ner.add_label(\"FUNC_PROG\")\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(3):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2000):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print 0 5 OPERATOR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Print\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">OPERATOR</span>\n",
       "</mark>\n",
       " variable i to screen</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(\"Print variable i to screen\")\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "displacy.render(nlp(doc.text), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set 0 3 COMMAND\n",
      "numbers 4 11 DATATYPE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    set\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">COMMAND</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    numbers\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATATYPE</span>\n",
       "</mark>\n",
       " a and b</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"set numbers a and b\")\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "displacy.render(nlp(doc.text), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get 0 3 COMMAND\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    get\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">COMMAND</span>\n",
       "</mark>\n",
       " input a</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#doc = nlp(\"create a function to add numbers a and b\")\n",
    "#doc = nlp(\"if a > b then add a and b\")\n",
    "doc = nlp(\"get input a\")\n",
    "#doc = nlp(\"if a>b then print a. If b>c then print c\")\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "displacy.render(nlp(doc.text), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the nlp Object\n",
    "nlp.to_disk(\"./NLP_Object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the nlp Object\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"./NLP_Object\")\n",
    "\n",
    "doc = nlp(\"create a function to add numbers a and b\")\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "displacy.render(nlp(doc.text), style=\"ent\", jupyter=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
